{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深入了解机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [线性回归](https://developers.google.cn/machine-learning/crash-course/descending-into-ml/linear-regression)\n",
    "\n",
    "```y = wx+b```\n",
    "- y 预测标签\n",
    "- w 特征的权重（直线的斜率）\n",
    "- x 特征\n",
    "- b 偏差（y轴截距）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [训练与损失](https://developers.google.cn/machine-learning/crash-course/descending-into-ml/training-and-loss)\n",
    "\n",
    "- **训练模型**表示通过有标签样本来学习（确定）所有权重和偏差的理想值。\n",
    "- 在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为**经验风险最小化**。\n",
    "- 训练模型的目标是从所有样本中找到一组平均损失“较小”的权重和偏差。\n",
    "- **均方误差 (MSE)** 指的是每个样本的平均平方损失。要计算 MSE，请求出各个样本的所有平方损失之和，然后除以样本数量。\n",
    "- 虽然 MSE 常用于机器学习，但它既不是唯一实用的损失函数，也不是适用于所有情形的最佳损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 误差\n",
    "\n",
    "- 误差反应了模型在预测任何给定样本时的效果如何。\n",
    "- L2误差，模型预测结果与真实值之间的平方差，简称**方差**。\n",
    "- 在训练模型时，并非专注于尽量减少某一个样本的误差，而是着眼于**最大限度地减少整个数据集**的误差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [视频讲座](https://developers.google.cn/machine-learning/crash-course/descending-into-ml/video-lecture)字幕\n",
    "\n",
    "```\n",
    "0:01\t正如我们之前介绍的， 我们通过研究数据得到了模型。\n",
    "0:04\t复杂的模型类型有很多，\n",
    "0:06\t我们用来研究数据的有趣方法也有很多。\n",
    "0:09\t但我们先从最简单、最熟悉的方法入手，\n",
    "0:11\t这能帮助我们了解更复杂的方法。\n",
    "0:15\t让我们以数据为基础， 用第一个小模型练习一下。\n",
    "0:18\t这里有一个小型数据集，\n",
    "0:20\tX轴是输入特征，\n",
    "0:23\t显示的是房子面积；\n",
    "0:26\tY轴是我们尝试预测的\n",
    "0:28\t房价的目标价值。\n",
    "0:31\t我们来试着制作一个模型，\n",
    "0:33\t将房子面积作为输入特征，\n",
    "0:36\t预测房价作为输出特征。\n",
    "0:39\t在我们的数据集中， 有很多用标签标出的小样本。\n",
    "0:42\t我准备引导具有初三学生 智力水平的机器画一条线。\n",
    "0:47\t它查看我们的数据集后，\n",
    "0:51\t大概会在这个位置画一条线， 差不多是这个样子。\n",
    "0:57\t这条线现在就是一个模型， 根据给定的输入值预测房价。\n",
    "1:05\t我们回想一下初中的代数， 可以将其定义为：\n",
    "1:10\ty=wx+b\n",
    "1:16\t而在高中代数中， 我们应该说mx。\n",
    "1:18\t但在这里我们说w， 因为讨论的是机器学习。\n",
    "1:21\t这指的是我们的权矢量。\n",
    "1:24\t您会发现这里有小下标，\n",
    "1:27\t因为我们可能有多个维度。\n",
    "1:30\tb表示偏差。\n",
    "1:33\tw表示斜率。\n",
    "1:36\t我们如何知道这条线是正确的呢？\n",
    "1:38\t这时我们可能需要考虑误差这一概念。\n",
    "1:42\t误差从本质上反映了\n",
    "1:46\t这条线在预测任何给定样本时的效果如何。\n",
    "1:50\t因此，我们可以通过观察\n",
    "1:51\t给定X值的预测结果 与相应样本真实值之间的差异，\n",
    "1:54\t来确定具体误差。\n",
    "1:56\t这个误差适中。\n",
    "1:59\t这个误差几乎为零。\n",
    "2:01\t这里的误差刚好为零。\n",
    "2:03\t这里的误差可能为正。\n",
    "2:06\t误差始终处于零到正数的范围之内。\n",
    "2:10\t我们如何定义误差呢？\n",
    "2:12\t在这方面，我们要考虑采取 稍微正式一些的方式。\n",
    "2:17\t让我们来想一个方便的方式 来定义回归问题中的误差。\n",
    "2:22\t不是只定义误差函数， 而是找出一个便于着手的实用方式。\n",
    "2:25\t我们将其称为L2误差， 也称为方差。\n",
    "2:29\t这是针对单个样本确定的误差，\n",
    "2:32\t采用我们模型的预测结果 与真实值之间的方差。\n",
    "2:37\t很明显，离真实值越远，\n",
    "2:41\t误差就会以平方数增加。\n",
    "2:45\t如今，我们在训练模型时， 并非专注于尽量减少某一个样本的误差，\n",
    "2:49\t而是着眼于最大限度地 减少整个数据集的误差。\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
